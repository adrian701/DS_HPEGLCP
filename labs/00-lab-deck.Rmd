---
title: "Brown Bag 01: Introduction"
author: ""
date: "2022-05-05"
output:
  xaringan::moon_reader:
    css: "lab-slides.css"
    logo: img/00/hpe_gl_logo.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
library(knitr)
opts_chunk$set(fig.height = 2.65, dpi = 300) 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
# For nonsese...
library(emo)
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
```

class: center, middle

# Welcome to HPE GLCS Data Science Brown Bag Series

---



## Who am I?


<img src="img/00/adrian_cartoon.png" style="display:block; margin: 0 auto; width: 20%">

Hi, I am <a href="../docs/adrian.html">Adrian Esparza</a>, data scientist for GL Cloud Services. Together, we will embark on a journey together of learning the tools, science and procedures behind data science! 




---

## Why? 



<img src="img/00/HPE_GreenLake_AI.png" style="display:block; margin: 0 auto; width: 100%">

<br>

> HPE has gone all in on edge-to-cloud with GreenLake services. 

<!--We are building software that run on our equipment. We are building them for a wide range of industries. We are building them for enterprises with have specific needs of managing their hybrid clouds more easily, protect and get more value from their data and securely connect at the edge. 

We understand our clients better. How they collaborate to create product and services, how they interact with the
--->

We believe there is value in understanding how companies and practitioners think about data and use AI to develop and deploy the technologies that are changing the world. 

<!-- And doing it an unprecedented rate. Moore's law, thank you. Talk about super computer  rushing to find the mrna vaccines in record times . Cheaper computing, storage and network improvement have ushered waves of companies like Netflix, FB, Google, Salesforce, Cisco, Alibaba and telecommunication companies. All these companies mine their data for insights and use it as a major competitive differentiator for today's landscape.

Companies are using digital exhaust as raw material to analyze and fuel better and better business decisions and predictions. And the digitial exhaust is now power.

Certainly, data scientists are required to build the analytics models — including machine learning and, increasingly, deep learning — capable of turning vast amounts of data into insights.

More recently, however, companies have widened their aperture, recognizing that success with AI and analytics requires not just data scientists but entire cross-functional, agile teams that include data engineers, data architects, data-visualization experts, and — perhaps most important — translators

Why are translators so important? They help ensure that organizations achieve real impact from their analytics initiatives (which has the added benefit of keeping data scientists fulfilled and more likely to stay on, easing executives’ stress over sourcing that talent).-->





---

## Strengthening our culture 


<img src="img/00/data_culture.png" style="display:block; margin: 0 auto; width: 90%">

> The digitization of everything from garbage collection to identifying fraud means that ever more of a good’s value derives from the software that operates it. The know-how needed to design, build, and deploy such software is yet another component of intangible capital that is fueling breakthrough transformations in our economy. 

---
## Making Complexity Invisible 


<img src="img/00/complex_ds2.jpeg" style="display:block; margin: 0 auto; width: 60%">

<!--
<img src="complex_ds.png" style="display:block; margin: 0 auto; width: 80%">

-->

> Software is the magical thing that takes each emerging form of complexity and abstracts it away.

We believe that as we engineer solutions for data scientist and AI algorithm engineers, not many of us know how data scientist analyze data in thoughtful and meaningful ways that empower companies and humanity to make better decisions. 

<!-- Reference Google photos. Think for second about a software application such as Google
Photos. Today it can pretty much recognize everything in every photo-
graph that you've ever stored on your computer. Twenty years ago, iwf your
spouse said to you, "Honey, find me some photos of our vacation on the
beach in Florida," you would have to manually go through photo album
after photo album, and shoe box after shoe box, to find them. Then photography became digital and you were able to upload all your photos online. Today, Google Photos backs up all your digital photos, organizes
them, labels them, and, using recognition software, enables you to find
any beach scene you're looking for with a few clicks or gestures, or maybe
even by just describing it verbally. In other words, the software has abstracted away all the complexity in that sorting and retrieval process and reduced it to a few keystrokes or touches or voice commands.-->

---

## Data Revolution

<img src="img/00/data_revolution.png" style="display:block; margin: 0 auto; width: 80%">



> Think about Uber doing all these steps

It created fundamentally a new and better way to summon a taxi, to gather data on rider's needs and desires, to pay for the rides, and to rate the behavior of the drivers and passagers. 

<!-- ## Removing the Friction -->

<!-- <img src="img/00/DS_various_collaborators.png" style="display:block; margin: 0 auto; width: 80%"> -->

<!-- > When DS stop worrying about what tools we are using, we can start focusing on what matters--mainly, creating value by solving problems. -->


<!-- we are getting all the friction out. When the world is flat you can put all the tools out there for everyone, but the system is stil full of friction. But the world is FAST when the tools disappear, and all you are thinking about is the project  -->
---

## Our footprint 

<img src="img/00/todays_offerings.png" style="display:block; margin: 0 auto; width: 145%">




<!-- although data scientist may produce good individial work, that work, more often than not, canot be reconciled within the large structures in place in their organization-->

---


class: center, middle

## Before we get started! Data Science Wordle of the Brown Bag!





---
### Brown Bag Wordle Topic

<img src="img/00/brownbag_wordle.png" style="display:block; margin: 0 auto; width: 105%">



---

<img src="img/00/data_science_process.jpeg" style="display:block; margin: 0 auto; width: 80%">



---
### Prerequisites 

1. High level understanding of Python and/or R
  - Code will be provided and discussed in each session but opportunities will exist for everyone to engage with the data and code their own functions.
2. Notebooks
  - Notebooks will be hosted on [Coogle Colab](https://www.youtube.com/embed/rNgswRZ2C1Y) preloaded with data and code used to analyze the data
  





---
### How?



<img src="img/00/sagemaker_colab_pythonR.png" style="display:block; margin: 0 auto; width: 100%">


* Colab is temporary hosting environment for our notebooks. We expect access to AWS equivalent, SageMaker Studio Lab, to come within the next month or so. 

---

### Brown Bag Program 

#### Cadence 
  - Bi-Weekly Brown Bag covering a set of topics related to the data science process 
    * Collection (we will skip this part since this falls more within data engineering)
    * Cleaning
    * Exploratory Data Analysis (critical and sometimes quite time consuming)
    * Model Building 
    * Model Deployment 
    
---

### Brown Bag Program Cont.

    
#### Labs

  - Presentation Labs Introducing the topics. 
    * We will use notebooks hosted on Google Colabs where everyone is encouraged to participate!
    * Will use a mix of Python/R and other open sources tools in public <p style="color:green;">cloud</p>
    * Couple of data sets will be used to drive the conversations about the data science process (also open source)
    
> Please visit website with updated brown bag sessions and content 

[Thinking in Data Science](https://adrian701.github.io/DS_HPEGLCP/)
  

---


class: center, middle

## Questions?

---

class: center, middle

# Let's get started!

---


### First use case: Prediction Bike-Sharing Demand

<img src="img/00/BikeShare_image.png" style="display:block; margin: 0 auto; width: 100%">

<img src="img/00/colab_notebook.png" style="display:block; margin: 0 auto; width: 100%">


<!--emphasis on goals, what do we want everyone to get out of it --->

